{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "392e0785-00a1-45bf-a899-b24ad281dc9d",
     "showTitle": true,
     "title": "Titanic 데이터 로드"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock sdf type: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+--------+------------+-----+------+------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+----------+------------+--------+--------+--------------+--------+\n",
      "|종목코드|      종목명| 종가|등락률|    시가총액|    기준일|   eps|  per|선행eps|선행per|     bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율| 시가| 고가| 저가|거래량|  거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|\n",
      "+--------+------------+-----+------+------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+----------+------------+--------+--------+--------------+--------+\n",
      "|  000020|    동화약품| 9350| -0.85|261159244500|2024-03-15| 736.0| 12.7|   null|   null| 13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02| 9450| 9450| 9300| 72206| 674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|\n",
      "|  000040|    KR모터스|  465|   0.0| 44704386225|2024-03-15|  null| null|   null|   null|   345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|    0|    0|    0|     0|         0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|\n",
      "|  000050|        경방| 8470| -1.63|232207336900|2024-03-15| 177.0|47.85|   null|   null| 30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99| 8610| 8690| 8270| 11024|  93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|\n",
      "|  000070|  삼양홀딩스|71300| -1.93|610632522300|2024-03-15|9173.0| 7.77|   null|   null|240995.0| 0.3|    3500.0|      4.91|        767205|        8.96|       8564271|            8.96|73000|74500|71300| 32624|2341408000|      126937|   KOSPI|  보통주|          소재|기타금융|\n",
      "|  000075|삼양홀딩스우|54900| -0.18| 16692784200|2024-03-15|  null| null|   null|   null|    null|null|    3550.0|      6.47|          4017|        1.32|        304058|            1.32|55400|55400|54800|    96|   5264000|        null|   KOSPI|  우선주|          null|기타금융|\n",
      "+--------+------------+-----+------+------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+----------+------------+--------+--------+--------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 객체 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"stock\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# pandas 버전\n",
    "# pandas_df = pd.read_csv('titanic_train.csv', header='infer')\n",
    "\n",
    "#spark.read.csv() 메소드를 이용하여 csv 파일을 로드하고 DataFrame으로 변환. \n",
    "# CSV 파일을 pandas 데이터프레임으로 불러올 때, 'NULL' 문자열을 NaN 값으로 대체하도록 설정\n",
    "stock_sdf = spark.read.csv('./data/stock_info_0315.csv', header=True, inferSchema=True,  nullValue='NULL')\n",
    "print('stock sdf type:', type(stock_sdf))\n",
    "\n",
    "stock_sdf.show(5)\n",
    "\n",
    "# spark DataFrame을 메모리에 cache\n",
    "stock_sdf = stock_sdf.cache()\n",
    "\n",
    "\n",
    "\n",
    "# pandas 데이터 불러오기 \n",
    "import pandas as pd\n",
    "\n",
    "na_values = ['NULL']\n",
    "stock_pdf = pd.read_csv('./data/stock_info_0315.csv', header='infer', na_values=na_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "caf8d92b-9c3a-4ed0-8c29-7cf00496f469",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Spark DataFrame의 withColumn() 메소드 알아보기\n",
    "* pandas DataFrame은 [] 을 이용하여 기존 컬럼값을 update, 또는 신규 컬럼 추가, 묵시적으로 컬럼 타입을 변경할 수 있음. 컬럼명 변경시는 rename()을 사용. 명시적인 컬럼 타입 변경은 astype()적용\n",
    "* spark DataFrame은 withColumn() 메소드를 이용하여 기존 컬럼값을 update, 컬럼 타입 변경, 신규 컬럼값을 추가할 수 있음. \n",
    "* withColumn('신규 또는 Update되는 컬럼명', '신규 또는 update되는 값')을 인자로 가짐. \n",
    "* 신규 또는 update되는 값을 생성 시에 기존 컬럼을 기반으로 한다면 신규 컬럼은 문자열로, 기존 컬럼은 반드시 컬럼형(col('컬럼명'))을 이용하여 적용.\n",
    "* 신규 컬럼값을 추가하는 것은 select() 메소드로도 가능\n",
    "* 컬럼명을 변경하는 것은 withColumnRename() 메소드로 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a46a7a5-d161-406a-8851-3ebc4bda3e0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2671 entries, 0 to 2670\n",
      "Data columns (total 28 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   종목코드      2671 non-null   object \n",
      " 1   종목명       2671 non-null   object \n",
      " 2   종가        2671 non-null   int64  \n",
      " 3   등락률       2671 non-null   float64\n",
      " 4   시가총액      2671 non-null   int64  \n",
      " 5   기준일       2671 non-null   object \n",
      " 6   eps       1600 non-null   float64\n",
      " 7   per       1600 non-null   float64\n",
      " 8   선행eps     511 non-null    float64\n",
      " 9   선행per     511 non-null    float64\n",
      " 10  bps       2381 non-null   float64\n",
      " 11  pbr       2381 non-null   float64\n",
      " 12  주당배당금     2622 non-null   float64\n",
      " 13  배당수익률     2622 non-null   float64\n",
      " 14  외국인보유수량   2671 non-null   int64  \n",
      " 15  외국인지분율    2671 non-null   float64\n",
      " 16  외국인한도수량   2671 non-null   int64  \n",
      " 17  외국인한도소진율  2671 non-null   float64\n",
      " 18  시가        2671 non-null   int64  \n",
      " 19  고가        2671 non-null   int64  \n",
      " 20  저가        2671 non-null   int64  \n",
      " 21  거래량       2671 non-null   int64  \n",
      " 22  거래대금      2671 non-null   int64  \n",
      " 23  기업고유번호    2554 non-null   float64\n",
      " 24  시장구분      2671 non-null   object \n",
      " 25  종목구분      2671 non-null   object \n",
      " 26  섹터        2276 non-null   object \n",
      " 27  업종명       2671 non-null   object \n",
      "dtypes: float64(12), int64(9), object(7)\n",
      "memory usage: 584.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>종목명</th>\n",
       "      <th>종가</th>\n",
       "      <th>등락률</th>\n",
       "      <th>시가총액</th>\n",
       "      <th>기준일</th>\n",
       "      <th>eps</th>\n",
       "      <th>per</th>\n",
       "      <th>선행eps</th>\n",
       "      <th>선행per</th>\n",
       "      <th>...</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>거래량</th>\n",
       "      <th>거래대금</th>\n",
       "      <th>기업고유번호</th>\n",
       "      <th>시장구분</th>\n",
       "      <th>종목구분</th>\n",
       "      <th>섹터</th>\n",
       "      <th>업종명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000020</td>\n",
       "      <td>동화약품</td>\n",
       "      <td>9350</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>261159244500</td>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>736.0</td>\n",
       "      <td>12.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9450</td>\n",
       "      <td>9450</td>\n",
       "      <td>9300</td>\n",
       "      <td>72206</td>\n",
       "      <td>674278570</td>\n",
       "      <td>119195.0</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>보통주</td>\n",
       "      <td>건강관리</td>\n",
       "      <td>의약품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000040</td>\n",
       "      <td>KR모터스</td>\n",
       "      <td>465</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44704386225</td>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112378.0</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>보통주</td>\n",
       "      <td>경기관련소비재</td>\n",
       "      <td>운수장비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000050</td>\n",
       "      <td>경방</td>\n",
       "      <td>8470</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>232207336900</td>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>177.0</td>\n",
       "      <td>47.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8610</td>\n",
       "      <td>8690</td>\n",
       "      <td>8270</td>\n",
       "      <td>11024</td>\n",
       "      <td>93485040</td>\n",
       "      <td>101628.0</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>보통주</td>\n",
       "      <td>경기관련소비재</td>\n",
       "      <td>유통업</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목코드    종목명    종가   등락률          시가총액         기준일    eps    per  선행eps  \\\n",
       "0  000020   동화약품  9350 -0.85  261159244500  2024-03-15  736.0  12.70    NaN   \n",
       "1  000040  KR모터스   465  0.00   44704386225  2024-03-15    NaN    NaN    NaN   \n",
       "2  000050     경방  8470 -1.63  232207336900  2024-03-15  177.0  47.85    NaN   \n",
       "\n",
       "   선행per  ...    시가    고가    저가    거래량       거래대금    기업고유번호   시장구분  종목구분  \\\n",
       "0    NaN  ...  9450  9450  9300  72206  674278570  119195.0  KOSPI   보통주   \n",
       "1    NaN  ...     0     0     0      0          0  112378.0  KOSPI   보통주   \n",
       "2    NaN  ...  8610  8690  8270  11024   93485040  101628.0  KOSPI   보통주   \n",
       "\n",
       "        섹터   업종명  \n",
       "0     건강관리   의약품  \n",
       "1  경기관련소비재  운수장비  \n",
       "2  경기관련소비재   유통업  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_pdf.info()\n",
    "stock_pdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "43276822-4006-481c-bb91-67d258cf5ae2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2671 entries, 0 to 2670\n",
      "Data columns (total 29 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   종목코드       2671 non-null   object \n",
      " 1   종목명        2671 non-null   object \n",
      " 2   종가         2671 non-null   int64  \n",
      " 3   등락률        2671 non-null   int64  \n",
      " 4   시가총액       2671 non-null   int64  \n",
      " 5   기준일        2671 non-null   object \n",
      " 6   eps        1600 non-null   float64\n",
      " 7   per        1600 non-null   float64\n",
      " 8   선행eps      511 non-null    float64\n",
      " 9   선행per      511 non-null    float64\n",
      " 10  bps        2381 non-null   float64\n",
      " 11  pbr        2381 non-null   float64\n",
      " 12  주당배당금      2622 non-null   float64\n",
      " 13  배당수익률      2622 non-null   float64\n",
      " 14  외국인보유수량    2671 non-null   int64  \n",
      " 15  외국인지분율     2671 non-null   float64\n",
      " 16  외국인한도수량    2671 non-null   int64  \n",
      " 17  외국인한도소진율   2671 non-null   float64\n",
      " 18  시가         2671 non-null   int64  \n",
      " 19  고가         2671 non-null   int64  \n",
      " 20  저가         2671 non-null   int64  \n",
      " 21  거래량        2671 non-null   int64  \n",
      " 22  거래대금       2671 non-null   int64  \n",
      " 23  기업고유번호     2554 non-null   float64\n",
      " 24  시장구분       2671 non-null   object \n",
      " 25  종목구분       2671 non-null   object \n",
      " 26  섹터         2276 non-null   object \n",
      " 27  업종명        2671 non-null   object \n",
      " 28  Extra_등락률  2671 non-null   float64\n",
      "dtypes: float64(12), int64(10), object(7)\n",
      "memory usage: 605.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>Extra_등락률</th>\n",
       "      <th>종가</th>\n",
       "      <th>등락률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>동화약품</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>10350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KR모터스</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경방</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>9470</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목명  Extra_등락률     종가  등락률\n",
       "0   동화약품      -85.0  10350    0\n",
       "1  KR모터스        0.0   1465    0\n",
       "2     경방     -163.0   9470   -1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "stock_pdf_copied = stock_pdf.copy()\n",
    "# Pandas DataFrame 신규 컬럼 추가\n",
    "stock_pdf_copied['Extra_등락률'] = stock_pdf_copied['등락률'] * 100\n",
    "# 기존 컬럼 update\n",
    "stock_pdf_copied['종가'] = stock_pdf_copied['종가'] + 1000\n",
    "# 기존 컬럼의 Data Type 변경.  \n",
    "stock_pdf_copied['등락률'] = stock_pdf_copied['등락률'].astype(np.int64)\n",
    "\n",
    "stock_pdf_copied.info()\n",
    "stock_pdf_copied[['종목명', 'Extra_등락률', '종가', '등락률']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1aa0320e-8fa7-4aff-b3c3-2c973f6db43b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 종목코드: string (nullable = true)\n",
      " |-- 종목명: string (nullable = true)\n",
      " |-- 종가: integer (nullable = true)\n",
      " |-- 등락률: integer (nullable = true)\n",
      " |-- 시가총액: long (nullable = true)\n",
      " |-- 기준일: date (nullable = true)\n",
      " |-- eps: double (nullable = true)\n",
      " |-- per: double (nullable = true)\n",
      " |-- 선행eps: double (nullable = true)\n",
      " |-- 선행per: double (nullable = true)\n",
      " |-- bps: double (nullable = true)\n",
      " |-- pbr: double (nullable = true)\n",
      " |-- 주당배당금: double (nullable = true)\n",
      " |-- 배당수익률: double (nullable = true)\n",
      " |-- 외국인보유수량: long (nullable = true)\n",
      " |-- 외국인지분율: double (nullable = true)\n",
      " |-- 외국인한도수량: long (nullable = true)\n",
      " |-- 외국인한도소진율: double (nullable = true)\n",
      " |-- 시가: integer (nullable = true)\n",
      " |-- 고가: integer (nullable = true)\n",
      " |-- 저가: integer (nullable = true)\n",
      " |-- 거래량: integer (nullable = true)\n",
      " |-- 거래대금: long (nullable = true)\n",
      " |-- 기업고유번호: integer (nullable = true)\n",
      " |-- 시장구분: string (nullable = true)\n",
      " |-- 종목구분: string (nullable = true)\n",
      " |-- 섹터: string (nullable = true)\n",
      " |-- 업종명: string (nullable = true)\n",
      " |-- Extra_등락률: double (nullable = true)\n",
      "\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+\n",
      "|종목코드|  종목명| 종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|Extra_등락률|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+\n",
      "|  000020|동화약품|10350|     0|261159244500|2024-03-15|736.0| 12.7|   null|   null|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|       -85.0|\n",
      "|  000040|KR모터스| 1465|     0| 44704386225|2024-03-15| null| null|   null|   null|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|         0.0|\n",
      "|  000050|    경방| 9470|    -1|232207336900|2024-03-15|177.0|47.85|   null|   null|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|      -163.0|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "stock_sdf_copied = stock_sdf.select('*') # stock_sdf 를 copy\n",
    "\n",
    "\n",
    "# withColumn('신규 또는 Update되는 컬럼명', '신규 또는 update되는 값')을 인자로 가짐. \n",
    "# 신규 또는 update되는 값을 생성 시에 기존 컬럼을 기반으로 한다면 신규 컬럼은 문자열로, 기존 컬럼은 반드시 컬럼형(col('컬럼명'))을 이용하여 적용\n",
    "# 신규 컬럼 Extra_등락률을 기존 컬럼 등락률을 이용하여 추가. 신규 컬럼은 'Extra_등락률' 문자열로, 기존 컬럼은 col('등락률')로 적용. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('Extra_등락률', col('등락률') * 100) \n",
    "\n",
    "# 기존 컬럼 종가 값을 update\n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('종가', col('종가') + 1000)\n",
    "\n",
    "# 기존 컬럼 등락률의 데이터 타입을 Integer로 변경. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('등락률', col('등락률').cast('Integer'))\n",
    "\n",
    "stock_sdf_copied.printSchema()\n",
    "stock_sdf_copied.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9d0480dd-1b44-4cf9-a7fe-18b9269154d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_COLUMN] Argument `col` should be a Column, got int.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 상수 값으로 update 시에 아래와 같이 수행하면 오류가 발생. 반드시 update할 값은 컬럼형이 되어야 함. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stock_sdf_copied \u001b[38;5;241m=\u001b[39m \u001b[43mstock_sdf_copied\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExtra_등락률\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:4785\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   4742\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4743\u001b[0m \u001b[38;5;124;03mReturns a new :class:`DataFrame` by adding a column or replacing the\u001b[39;00m\n\u001b[1;32m   4744\u001b[0m \u001b[38;5;124;03mexisting column that has the same name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4782\u001b[0m \u001b[38;5;124;03m+---+-----+----+\u001b[39;00m\n\u001b[1;32m   4783\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m-> 4785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   4786\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4787\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   4788\u001b[0m     )\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mwithColumn(colName, col\u001b[38;5;241m.\u001b[39m_jc), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_COLUMN] Argument `col` should be a Column, got int."
     ]
    }
   ],
   "source": [
    "# 상수 값으로 update 시에 아래와 같이 수행하면 오류가 발생. 반드시 update할 값은 컬럼형이 되어야 함. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('Extra_등락률', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "71bd8a47-f2ab-4043-9394-3dec1ee1a217",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+\n",
      "|종목코드|  종목명| 종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|Extra_등락률|Extra_values| New_Name|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+\n",
      "|  000020|동화약품|10350|     0|261159244500|2024-03-15|736.0| 12.7|   null|   null|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|       -85.0|          10|Test_name|\n",
      "|  000040|KR모터스| 1465|     0| 44704386225|2024-03-15| null| null|   null|   null|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|         0.0|          10|Test_name|\n",
      "|  000050|    경방| 9470|    -1|232207336900|2024-03-15|177.0|47.85|   null|   null|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|      -163.0|          10|Test_name|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# 상수 값으로 update 시 반드시 lit() 함수를 적용하여야 함. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('Extra_values', lit(10))\n",
    "\n",
    "# 상수 값으로 신규 컬럼 생성시에도 반드시 lit() 함수를 적용해야 함. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('New_Name', lit('Test_name'))\n",
    "\n",
    "stock_sdf_copied.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "75519a65-257e-4acb-8027-b9a893aeda21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+-------------+--------------+\n",
      "|종목코드|  종목명| 종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|Extra_등락률|Extra_values| New_Name|closing_price|stock_division|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+-------------+--------------+\n",
      "|  000020|동화약품|10350|     0|261159244500|2024-03-15|736.0| 12.7|   null|   null|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|       -85.0|          10|Test_name|        10350|          보통|\n",
      "|  000040|KR모터스| 1465|     0| 44704386225|2024-03-15| null| null|   null|   null|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|         0.0|          10|Test_name|         1465|          보통|\n",
      "|  000050|    경방| 9470|    -1|232207336900|2024-03-15|177.0|47.85|   null|   null|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|      -163.0|          10|Test_name|         9470|          보통|\n",
      "+--------+--------+-----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+------------+------------+---------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, substring\n",
    "\n",
    "# select() 메소드를 이용하여 컬럼 추가. SQL substring() 함수를 이용하여 문자열의 일부를 추출하여 신규 컬럼 생성. \n",
    "\n",
    "# select a.*, 종가 as closing_price from stock_sdf a\n",
    "stock_sdf_copied = stock_sdf_copied.select('*', col('종가').alias('closing_price'))\n",
    "\n",
    "# select a.*, substring('종목구분', 0, 1) as stock_division from stock_sdf a\n",
    "stock_sdf_copied = stock_sdf_copied.select('*', substring('종목구분', 0, 2).alias('stock_division')) \n",
    "\n",
    "\n",
    "stock_sdf_copied.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36b00c5c-3314-401e-8372-5f6fc32faa1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Name1|Name2|\n",
      "+-----+-----+\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "|    K|  SPI|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "# SQL function split()을 이용하여 문자열을 ','로 분리하여 새로운 컬럼명 Name1, Name2 생성. \n",
    "# O 문자를 기준으로 split하여 첫번째 요소 반환 \n",
    "stock_sdf_copied = stock_sdf_copied.withColumn('Name1', split(col('시장구분'), 'O').getItem(0))\n",
    "# O 문자를 기준으로 split하여 두번째 요소 반환 \n",
    "stock_sdf_copied  = stock_sdf_copied.withColumn('Name2', split(col('시장구분'), 'O').getItem(1))\n",
    "\n",
    "\n",
    "stock_sdf_copied.select(\"Name1\", \"Name2\").limit(10).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58042d66-01c7-4dd3-9eab-41c4df219c87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------------+\n",
      "|market_division|stock_code|    stock_name|\n",
      "+---------------+----------+--------------+\n",
      "|          KOSPI|    000020|      동화약품|\n",
      "|          KOSPI|    000040|      KR모터스|\n",
      "|          KOSPI|    000050|          경방|\n",
      "|          KOSPI|    000070|    삼양홀딩스|\n",
      "|          KOSPI|    000075|  삼양홀딩스우|\n",
      "|          KOSPI|    000080|    하이트진로|\n",
      "|          KOSPI|    000087|하이트진로2우B|\n",
      "|          KOSPI|    000100|      유한양행|\n",
      "|          KOSPI|    000105|    유한양행우|\n",
      "|          KOSPI|    000120|    CJ대한통운|\n",
      "+---------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumnRenamed('기존 컬럼명', '변경 컬럼명')으로 컬럼명 변경. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumnRenamed('시장구분', 'market_division')\n",
    "stock_sdf_copied = stock_sdf_copied.withColumnRenamed('종목코드', 'stock_code')\n",
    "\n",
    "#변경하려는 컬럼명이 없어도 오류를 발생 시키지 않음. 유의 필요. \n",
    "stock_sdf_copied = stock_sdf_copied.withColumnRenamed('시장 구분_X', 'market_division_X')\n",
    "\n",
    "stock_sdf_copied.select('market_division', 'stock_code', col('종목명').alias('stock_name')).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e89439b0-28f9-40d5-aaa4-c990fa23a1e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Spark DataFrame의 컬럼 삭제와 로우(레코드) 삭제\n",
    "* Pandas DataFrame은 drop() 메소드의 axis를 기반으로 컬럼(axis=1) 또는 로우(axis=0)를 삭제할 수 있으나\n",
    "* Spark DataFrame drop() 메소드는 컬럼 삭제만 가능. 단일/여러개의 컬럼을 삭제 할 수 있음. 단 여러개의 컬럼 삭제 시 list로 입력 할 수 없으며 개별 컬럼명들이 입력되어야 함. \n",
    "* Spark DataFrame은 기본적으로는 특정 조건에 따른 로우 삭제가 어려움. 로우 삭제 대신 filter() 메소드를 이용하여 해당 조건의 데이터를 다시 만들어냄. \n",
    "* Pandas의 None 값을 Null을 의미하여 Spark에서는 null로 변환됨. \n",
    "* 값이 있는 record는 dropna() 메소드 또는 DataFrame.na.drop()을 이용하여 삭제 할 수 있음. 또는 filter() 조건에서 Not null조건으로 다시 만들어 냄.\n",
    "* DataFrame.na는 DataFrameNaFunctions 객체임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9a99ed86-bea0-47bd-a160-f432a6484a4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['종목코드', '종가', '등락률', '시가총액', '기준일', 'eps', 'per', '선행eps', '선행per',\n",
       "       'bps', 'pbr', '주당배당금', '배당수익률', '외국인보유수량', '외국인지분율', '외국인한도수량',\n",
       "       '외국인한도소진율', '시가', '고가', '저가', '거래량', '거래대금', '기업고유번호', '시장구분', '종목구분',\n",
       "       '섹터', '업종명'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_pdf_dropped = stock_pdf.drop('종목명', axis=1, inplace=False)\n",
    "stock_pdf_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e754bac2-433b-4f6c-ab27-c9a7b49e3c0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['종목코드',\n",
       " '종가',\n",
       " '등락률',\n",
       " '시가총액',\n",
       " '기준일',\n",
       " 'eps',\n",
       " 'per',\n",
       " '선행eps',\n",
       " '선행per',\n",
       " 'bps',\n",
       " 'pbr',\n",
       " '주당배당금',\n",
       " '배당수익률',\n",
       " '외국인보유수량',\n",
       " '외국인지분율',\n",
       " '외국인한도수량',\n",
       " '외국인한도소진율',\n",
       " '시가',\n",
       " '고가',\n",
       " '저가',\n",
       " '거래량',\n",
       " '거래대금',\n",
       " '기업고유번호',\n",
       " '시장구분',\n",
       " '종목구분',\n",
       " '섹터',\n",
       " '업종명']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "stock_sdf_copied = stock_sdf.select('*')\n",
    "\n",
    "# 단일 컬럼 삭제. drop() 메소드 인자로 단일 컬럼명 문자열, 또는 컬럼명 컬럼형을 입력. \n",
    "stock_sdf_copied = stock_sdf_copied.drop('종목명')\n",
    "# drop 컬럼이 존재하지 않아도 오류가 발생하지 않음. 유의 필요. \n",
    "stock_sdf_copied = stock_sdf_copied.drop(col('종목명_ㅌ'))\n",
    "\n",
    "stock_sdf_copied.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "67f1d727-5613-488a-b6e6-931d7d993b68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['등락률',\n",
       " '시가총액',\n",
       " '기준일',\n",
       " 'eps',\n",
       " 'per',\n",
       " '선행eps',\n",
       " '선행per',\n",
       " 'bps',\n",
       " 'pbr',\n",
       " '주당배당금',\n",
       " '배당수익률',\n",
       " '외국인보유수량',\n",
       " '외국인지분율',\n",
       " '외국인한도수량',\n",
       " '외국인한도소진율',\n",
       " '시가',\n",
       " '고가',\n",
       " '저가',\n",
       " '거래량',\n",
       " '거래대금',\n",
       " '기업고유번호',\n",
       " '시장구분',\n",
       " '종목구분',\n",
       " '섹터',\n",
       " '업종명']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "#여러개의 컬럼을 삭제할 시 list가 아니라 단일 컬럼명들을 각각 인자로 넣어 주어야 함. \n",
    "stock_sdf_copied.drop('종목코드', '종가').limit(3).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['등락률',\n",
       " '시가총액',\n",
       " '기준일',\n",
       " 'eps',\n",
       " 'per',\n",
       " '선행eps',\n",
       " '선행per',\n",
       " 'bps',\n",
       " 'pbr',\n",
       " '주당배당금',\n",
       " '배당수익률',\n",
       " '외국인보유수량',\n",
       " '외국인지분율',\n",
       " '외국인한도수량',\n",
       " '외국인한도소진율',\n",
       " '시가',\n",
       " '고가',\n",
       " '저가',\n",
       " '거래량',\n",
       " '거래대금',\n",
       " '기업고유번호',\n",
       " '시장구분',\n",
       " '종목구분',\n",
       " '섹터',\n",
       " '업종명']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래는 오류 발생. 여러개의 컬럼들을 삭제 시 컬럼형 인자는 안됨(3.2 버전에서는 오류가 나지만, 3.4 버전에서는 정상 출력)\n",
    "stock_sdf_copied.drop(col('종목코드'), col('종가')).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74a551ee-2493-4416-b327-b973baf650a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_code closing_price\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['종목코드', '종가']\n",
    "print(*drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cbd8aed8-cc90-4f58-b331-03bd2b3aaf0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "|등락률|     시가총액|    기준일|   eps|  per|선행eps|선행per|     bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|  시가|  고가|  저가|거래량|   거래대금|기업고유번호|시장구분|종목구분|          섹터|    업종명|\n",
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "| -0.85| 261159244500|2024-03-15| 736.0| 12.7|   null|   null| 13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|  9450|  9450|  9300| 72206|  674278570|      119195|   KOSPI|  보통주|      건강관리|    의약품|\n",
      "|   0.0|  44704386225|2024-03-15|  null| null|   null|   null|   345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|     0|     0|     0|     0|          0|      112378|   KOSPI|  보통주|경기관련소비재|  운수장비|\n",
      "| -1.63| 232207336900|2024-03-15| 177.0|47.85|   null|   null| 30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|  8610|  8690|  8270| 11024|   93485040|      101628|   KOSPI|  보통주|경기관련소비재|    유통업|\n",
      "| -1.93| 610632522300|2024-03-15|9173.0| 7.77|   null|   null|240995.0| 0.3|    3500.0|      4.91|        767205|        8.96|       8564271|            8.96| 73000| 74500| 71300| 32624| 2341408000|      126937|   KOSPI|  보통주|          소재|  기타금융|\n",
      "| -0.18|  16692784200|2024-03-15|  null| null|   null|   null|    null|null|    3550.0|      6.47|          4017|        1.32|        304058|            1.32| 55400| 55400| 54800|    96|    5264000|        null|   KOSPI|  우선주|          null|  기타금융|\n",
      "|   0.0|1423712303300|2024-03-15|1250.0|16.24| 1265.0|  16.05| 16906.0| 1.2|     950.0|      4.68|       7777084|       11.09|      70133611|           11.09| 20300| 20300| 19960|154102| 3103992290|      150244|   KOSPI|  보통주|    필수소비재|  음식료품|\n",
      "|  0.58|  17754467980|2024-03-15|  null| null|   null|   null|    null|null|    1000.0|      6.37|          4836|        0.43|       1130138|            0.43| 15530| 15720| 15530|   508|    7934080|        null|   KOSPI|  우선주|          null|  음식료품|\n",
      "|  -1.6|5935470736000|2024-03-15|1272.0|58.18| 2145.0|   34.5| 27137.0|2.73|     400.0|      0.54|      16063263|       20.03|      80209064|           20.03| 76200| 77800| 73700|634851|47632579300|      145109|   KOSPI|  보통주|      건강관리|    의약품|\n",
      "| -2.46|  74871596000|2024-03-15|  null| null|   null|   null|    null|null|     410.0|      0.65|             0|         0.0|       1180940|             0.0| 65000| 65800| 63200|  1952|  125010900|        null|   KOSPI|  우선주|          null|    의약품|\n",
      "| -1.19|2842418062400|2024-03-15|8190.0|15.21|12469.0|   9.99|179031.0| 0.7|     500.0|       0.4|       2998297|       13.14|      22812344|           13.14|122800|126200|120100|100113|12413223600|      113410|   KOSPI|  보통주|        산업재|운수창고업|\n",
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "\n",
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "|등락률|     시가총액|    기준일|   eps|  per|선행eps|선행per|     bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|  시가|  고가|  저가|거래량|   거래대금|기업고유번호|시장구분|종목구분|          섹터|    업종명|\n",
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "| -0.85| 261159244500|2024-03-15| 736.0| 12.7|   null|   null| 13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|  9450|  9450|  9300| 72206|  674278570|      119195|   KOSPI|  보통주|      건강관리|    의약품|\n",
      "|   0.0|  44704386225|2024-03-15|  null| null|   null|   null|   345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|     0|     0|     0|     0|          0|      112378|   KOSPI|  보통주|경기관련소비재|  운수장비|\n",
      "| -1.63| 232207336900|2024-03-15| 177.0|47.85|   null|   null| 30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|  8610|  8690|  8270| 11024|   93485040|      101628|   KOSPI|  보통주|경기관련소비재|    유통업|\n",
      "| -1.93| 610632522300|2024-03-15|9173.0| 7.77|   null|   null|240995.0| 0.3|    3500.0|      4.91|        767205|        8.96|       8564271|            8.96| 73000| 74500| 71300| 32624| 2341408000|      126937|   KOSPI|  보통주|          소재|  기타금융|\n",
      "| -0.18|  16692784200|2024-03-15|  null| null|   null|   null|    null|null|    3550.0|      6.47|          4017|        1.32|        304058|            1.32| 55400| 55400| 54800|    96|    5264000|        null|   KOSPI|  우선주|          null|  기타금융|\n",
      "|   0.0|1423712303300|2024-03-15|1250.0|16.24| 1265.0|  16.05| 16906.0| 1.2|     950.0|      4.68|       7777084|       11.09|      70133611|           11.09| 20300| 20300| 19960|154102| 3103992290|      150244|   KOSPI|  보통주|    필수소비재|  음식료품|\n",
      "|  0.58|  17754467980|2024-03-15|  null| null|   null|   null|    null|null|    1000.0|      6.37|          4836|        0.43|       1130138|            0.43| 15530| 15720| 15530|   508|    7934080|        null|   KOSPI|  우선주|          null|  음식료품|\n",
      "|  -1.6|5935470736000|2024-03-15|1272.0|58.18| 2145.0|   34.5| 27137.0|2.73|     400.0|      0.54|      16063263|       20.03|      80209064|           20.03| 76200| 77800| 73700|634851|47632579300|      145109|   KOSPI|  보통주|      건강관리|    의약품|\n",
      "| -2.46|  74871596000|2024-03-15|  null| null|   null|   null|    null|null|     410.0|      0.65|             0|         0.0|       1180940|             0.0| 65000| 65800| 63200|  1952|  125010900|        null|   KOSPI|  우선주|          null|    의약품|\n",
      "| -1.19|2842418062400|2024-03-15|8190.0|15.21|12469.0|   9.99|179031.0| 0.7|     500.0|       0.4|       2998297|       13.14|      22812344|           13.14|122800|126200|120100|100113|12413223600|      113410|   KOSPI|  보통주|        산업재|운수창고업|\n",
      "+------+-------------+----------+------+-----+-------+-------+--------+----+----------+----------+--------------+------------+--------------+----------------+------+------+------+------+-----------+------------+--------+--------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['종목코드', '종가']\n",
    "drop_columns_col = [col('종목코드'), col('종가')]\n",
    "\n",
    "stock_sdf_copied.drop(*drop_columns).limit(10).show()\n",
    "\n",
    "stock_sdf_copied.drop(*drop_columns_col).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc7fca33-19f8-4e29-bdcb-701799e98e91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stock_name', 'string'),\n",
       " ('closing_price', 'bigint'),\n",
       " ('price_change', 'double'),\n",
       " ('market_cap', 'bigint'),\n",
       " ('base_date', 'string'),\n",
       " ('eps', 'double'),\n",
       " ('per', 'double'),\n",
       " ('leading_eps', 'double'),\n",
       " ('leading_per', 'double'),\n",
       " ('bps', 'double'),\n",
       " ('pbr', 'double'),\n",
       " ('dividend_per_share', 'double'),\n",
       " ('dividend_yield', 'double'),\n",
       " ('foreign_ownership_quantity', 'bigint'),\n",
       " ('foreign_ownership_ratio', 'double'),\n",
       " ('foreign_limit_quantity', 'bigint'),\n",
       " ('foreign_limit_exhaustion_ratio', 'double'),\n",
       " ('opening_price', 'bigint'),\n",
       " ('high_price', 'bigint'),\n",
       " ('low_price', 'bigint'),\n",
       " ('trading_volume', 'bigint'),\n",
       " ('trading_value', 'bigint'),\n",
       " ('company_id', 'double'),\n",
       " ('market_division', 'string'),\n",
       " ('stock_division', 'string'),\n",
       " ('sector', 'string'),\n",
       " ('industry_name', 'string')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_sdf_copied.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54f828ab-d005-4bf2-b7e8-a56ef1e7916c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop 컬럼명: ['stock_name', 'base_date', 'market_division', 'stock_division', 'sector', 'industry_name']\n",
      "+-------------+------------+-------------+------+-----+-----------+-----------+--------+----+------------------+--------------+--------------------------+-----------------------+----------------------+------------------------------+-------------+----------+---------+--------------+-------------+----------+\n",
      "|closing_price|price_change|   market_cap|   eps|  per|leading_eps|leading_per|     bps| pbr|dividend_per_share|dividend_yield|foreign_ownership_quantity|foreign_ownership_ratio|foreign_limit_quantity|foreign_limit_exhaustion_ratio|opening_price|high_price|low_price|trading_volume|trading_value|company_id|\n",
      "+-------------+------------+-------------+------+-----+-----------+-----------+--------+----+------------------+--------------+--------------------------+-----------------------+----------------------+------------------------------+-------------+----------+---------+--------------+-------------+----------+\n",
      "|         9350|       -0.85| 261159244500| 736.0| 12.7|        NaN|        NaN| 13165.0|0.71|             180.0|          1.93|                   1681856|                   6.02|              27931470|                          6.02|         9450|      9450|     9300|         72206|    674278570|  119195.0|\n",
      "|          465|         0.0|  44704386225|   NaN|  NaN|        NaN|        NaN|   345.0|1.35|               0.0|           0.0|                  43963412|                  45.73|              96138465|                         45.73|            0|         0|        0|             0|            0|  112378.0|\n",
      "|         8470|       -1.63| 232207336900| 177.0|47.85|        NaN|        NaN| 30304.0|0.28|             125.0|          1.48|                    270629|                   0.99|              27415270|                          0.99|         8610|      8690|     8270|         11024|     93485040|  101628.0|\n",
      "|        71300|       -1.93| 610632522300|9173.0| 7.77|        NaN|        NaN|240995.0| 0.3|            3500.0|          4.91|                    767205|                   8.96|               8564271|                          8.96|        73000|     74500|    71300|         32624|   2341408000|  126937.0|\n",
      "|        54900|       -0.18|  16692784200|   NaN|  NaN|        NaN|        NaN|     NaN| NaN|            3550.0|          6.47|                      4017|                   1.32|                304058|                          1.32|        55400|     55400|    54800|            96|      5264000|       NaN|\n",
      "|        20300|         0.0|1423712303300|1250.0|16.24|     1265.0|      16.05| 16906.0| 1.2|             950.0|          4.68|                   7777084|                  11.09|              70133611|                         11.09|        20300|     20300|    19960|        154102|   3103992290|  150244.0|\n",
      "|        15710|        0.58|  17754467980|   NaN|  NaN|        NaN|        NaN|     NaN| NaN|            1000.0|          6.37|                      4836|                   0.43|               1130138|                          0.43|        15530|     15720|    15530|           508|      7934080|       NaN|\n",
      "|        74000|        -1.6|5935470736000|1272.0|58.18|     2145.0|       34.5| 27137.0|2.73|             400.0|          0.54|                  16063263|                  20.03|              80209064|                         20.03|        76200|     77800|    73700|        634851|  47632579300|  145109.0|\n",
      "|        63400|       -2.46|  74871596000|   NaN|  NaN|        NaN|        NaN|     NaN| NaN|             410.0|          0.65|                         0|                    0.0|               1180940|                           0.0|        65000|     65800|    63200|          1952|    125010900|       NaN|\n",
      "|       124600|       -1.19|2842418062400|8190.0|15.21|    12469.0|       9.99|179031.0| 0.7|             500.0|           0.4|                   2998297|                  13.14|              22812344|                         13.14|       122800|    126200|   120100|        100113|  12413223600|  113410.0|\n",
      "+-------------+------------+-------------+------+-----+-----------+-----------+--------+----+------------------+--------------+--------------------------+-----------------------+----------------------+------------------------------+-------------+----------+---------+--------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 아래와 같이 logic으로 조건에 맞는 여러개의 컬럼들을 삭제할 수 있음. \n",
    "drop_string_columns = [ column_name for column_name, column_type in stock_sdf_copied.dtypes if column_type == 'string']\n",
    "print('drop 컬럼명:', drop_string_columns)\n",
    "stock_sdf_copied.drop(*drop_string_columns).limit(10).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8bf57706-5409-49cb-abdf-72ad04f9620e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------+\n",
      "|      종목명|    섹터|시장구분|\n",
      "+------------+--------+--------+\n",
      "|  삼천당제약|건강관리|  KOSDAQ|\n",
      "|중앙에너비스|  에너지|  KOSDAQ|\n",
      "|    신라섬유|      IT|  KOSDAQ|\n",
      "+------------+--------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark DataFrame은 특정 조건으로 로우를 삭제하기가 어려우므로 filter()로 특정 조건에 해당하지 않는 로우를 걸러내는 방식을 적용. \n",
    "stock_sdf_removed_market_division_kospi = stock_sdf.filter(col('시장구분') != 'KOSPI')\n",
    "stock_sdf_removed_market_division_kospi.select('종목명', '섹터', '시장구분').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_pdf count: 2671\n",
      "dropna()적용 후 count: 395\n"
     ]
    }
   ],
   "source": [
    "# 하나라도 null또는 nan 값이 있으면 삭제한 결과 DataFrame을 반환. \n",
    "print('stock_pdf count:', stock_pdf.shape[0])\n",
    "\n",
    "# DataFrame의 dropna()메소드는 레코드에 하나라도 null또는 nan 값이 있으면 삭제한 결과 DataFrame을 반환. \n",
    "stock_pdf_dropna_01 = stock_pdf.dropna()\n",
    "print('dropna()적용 후 count:', stock_pdf_dropna_01.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25308ab7-19fe-4667-813d-1cec8c2f2c15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_sdf count: 2671\n",
      "dropna()적용 후 count: 395\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "print('stock_sdf count:', stock_sdf.count())\n",
    "\n",
    "# DataFrame의 dropna()메소드는 레코드에 하나라도 null또는 nan 값이 있으면 삭제한 결과 DataFrame을 반환. \n",
    "stock_sdf_dropna_01 = stock_sdf.dropna()\n",
    "print('dropna()적용 후 count:', stock_sdf_dropna_01.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cc6f077a-782a-4447-a180-7d0fbddadcf6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.na.drop()적용 후 count: 395\n",
      "stock_sdf.na 타입: <class 'pyspark.sql.dataframe.DataFrameNaFunctions'>\n"
     ]
    }
   ],
   "source": [
    "stock_sdf_dropna_02 = stock_sdf.na.drop()\n",
    "print('DataFrame.na.drop()적용 후 count:', stock_sdf_dropna_02.count())\n",
    "print('stock_sdf.na 타입:', type(stock_sdf.na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3dd6bdfe-574c-4383-a20d-f92ab92414ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.na.drop()을 per와 eps 컬럼 적용 후 count: 1600\n"
     ]
    }
   ],
   "source": [
    "# 특정 컬럼에 Null 이 있는 경우에만 삭제할 경우\n",
    "stock_sdf_dropna_03 = stock_sdf.na.drop(subset=[\"per\", \"eps\"]) \n",
    "print('DataFrame.na.drop()을 per와 eps 컬럼 적용 후 count:', stock_sdf_dropna_03.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d07096db-c7e1-4c2b-9121-2d27870764cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pandas와 Spark에서의 None, Null, NaN 의 구분 - 1\n",
    "* Python은 None이라는 값이 없는 내장 상수가 있음. None 객체라고도 부리면 이는 NoneType 클래스임. \n",
    "* SQL은 원론적으로 None이 아니라 Null 임. \n",
    "* numpy는 python None은 처리하기 위해 object 형으로 None을 할당할수 있고, float 형으로 NaN을 할당 할 수 있음. \n",
    "* NaN은 원래 Not a Number라는 의미임. 숫자형 array에 값이 없을 경우에는 NaN을 할당함. \n",
    "* pandas는 csv와 같은 파일에서 로드 시 특정 컬럼에 데이터가 없을 경우에 문자열 컬럼일 경우 None으로 숫자형 컬럼일 경우 NaN으로 할당. 단 NaN 으로 할당 시에는 int형 컬럼이라도 float형으로 변경됨. \n",
    "* Spark는 csv와 같은 파일에서 로드 시 모든 컬럼을 다 Null로 변환. 기본적으로 None은 Null에 할당. 이는 SQL사상과 동일. \n",
    "* 하지만 Spark는 pandas DataFrame의 NaN 처리와 어느정도 호환성을 유지하기 위해 NaN도 함께 지원.\n",
    "* 과거 버전 Spark(Spark 3.0 이하)는 pandas DataFrame을 spark로 변환 시에 NaN 값을 동일하게 NaN으로 변환하였으나 현재는 null로 변환함. 하지만 NaN 값을 명확하게 지정하여 spark DataFrame을 만들 수 있음.\n",
    "* 결론적으로 NaN은 고려하지 않고 Null만 고려할 수 있도록 Spark DataFrame을 만드는 것이 중요. isnan()은 사용하지 않고, isNull()만 사용할 수 있도록 유도."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9098e325-ac3a-4273-8bd8-ba49b1fc4ba8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'> None\n"
     ]
    }
   ],
   "source": [
    "val = None\n",
    "print(type(val), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eafac9c1-f039-42b2-96e3-54c59f17ae00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 None]\n",
      "[ 0.  1.  2. nan]\n",
      "[ 0.  1.  2. nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# None은 object형 array에만 넣을 수 있음. \n",
    "array = np.array([0, 1, 2, None])\n",
    "print(array)\n",
    "\n",
    "# None을 숫자형(np.int는 안되고 np.float)로 입력할 경우는 NaN으로 입력됨. \n",
    "array = np.array([0, 1, 2, None], dtype=np.float64)\n",
    "print(array)\n",
    "\n",
    "array = np.array([0, 1, 2, np.NaN], dtype=np.float64)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1b15929-6bee-4e8d-a159-03445cd5dee2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  x|   y|\n",
      "+---+----+\n",
      "|1.0|null|\n",
      "|NaN| foo|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark 3.2 에서는 pandas DataFrame의 NaN을 spark DataFrame으로 변환 시 Null로 변환. spark 3.0 이하 버전에서는 NaN 으로 변환\n",
    "# Spark 3.4 버전에서는 NaN 으로 변환(현재 사용 버전)\n",
    "pdf = pd.DataFrame({\n",
    "    \"x\": [1, np.NaN], \"y\": [None, \"foo\"]\n",
    "})\n",
    "sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7167c28-dbdc-49be-825f-101535d2d639",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  x|   y|\n",
      "+---+----+\n",
      "|1.0|null|\n",
      "|NaN| foo|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 직접 NaN값을 지정하여 입력할 경우 Spark DataFrame에 NaN 입력 가능. \n",
    "sdf = spark.createDataFrame([(1.0, None), (float('nan'), 'foo')], (\"x\", \"y\"))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23393999-8040-4db4-bff1-ccadce743068",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Spark DataFrame에서 Null과 NaN 찾기\n",
    "* pandas DataFrame의 isnull()과 isna()는 서로 동일한 메소드임. isnull(), isna() 모두 None과 NaN을 모두 찾음. \n",
    "* spark DataFrame isNull()은 null만 찾아줌, isnan()은 NaN만 찾음. 또한 isNull()은 컬럼 조건에 붙어서 filter()메소드와 함께 사용되며, isnan()은 pyspark.sql.functions의 함수로 정의됨.\n",
    "* spark DataFrame의 dropna() 메소드는 NaN과 Null 모두를 찾아서 삭제해줌.\n",
    "* Not Null 조건으로 찾을 때는 isNotNull() 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e365e45-c19d-4f74-b83e-e20ac76ece70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        종목명    per\n",
      "0      동화약품  12.70\n",
      "1     KR모터스    NaN\n",
      "2        경방  47.85\n",
      "3     삼양홀딩스   7.77\n",
      "4    삼양홀딩스우    NaN\n",
      "5     하이트진로  16.24\n",
      "6  하이트진로2우B    NaN\n",
      "7      유한양행  58.18\n",
      "8     유한양행우    NaN\n",
      "9    CJ대한통운  15.21\n",
      "### isna() 적용 결과 ### \n",
      "     종목명    per\n",
      "0  False  False\n",
      "1  False   True\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False   True\n",
      "5  False  False\n",
      "6  False   True\n",
      "7  False  False\n",
      "8  False   True\n",
      "9  False  False\n",
      "### isnull() 적용 결과 ### \n",
      "     종목명    per\n",
      "0  False  False\n",
      "1  False   True\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False   True\n",
      "5  False  False\n",
      "6  False   True\n",
      "7  False  False\n",
      "8  False   True\n",
      "9  False  False\n"
     ]
    }
   ],
   "source": [
    "print(stock_pdf[['종목명', 'per']].head(10))\n",
    "print('### isna() 적용 결과 ### ')\n",
    "print(stock_pdf[['종목명', 'per']].isna().head(10))\n",
    "\n",
    "print('### isnull() 적용 결과 ### ')\n",
    "print(stock_pdf[['종목명', 'per']].isnull().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e45ec67-971e-4964-8b3e-b49d91f260a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### isNull() 적용 결과 #####\n",
      "+--------+--------------+-----+------+-----------+----------+----+----+-------+-------+-----+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+--------+------------+--------+--------+--------------+--------+\n",
      "|종목코드|        종목명| 종가|등락률|   시가총액|    기준일| eps| per|선행eps|선행per|  bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율| 시가| 고가| 저가|거래량|거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|\n",
      "+--------+--------------+-----+------+-----------+----------+----+----+-------+-------+-----+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+--------+------------+--------+--------+--------------+--------+\n",
      "|  000040|      KR모터스|  465|   0.0|44704386225|2024-03-15|null|null|   null|   null|345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|    0|    0|    0|     0|       0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|\n",
      "|  000075|  삼양홀딩스우|54900| -0.18|16692784200|2024-03-15|null|null|   null|   null| null|null|    3550.0|      6.47|          4017|        1.32|        304058|            1.32|55400|55400|54800|    96| 5264000|        null|   KOSPI|  우선주|          null|기타금융|\n",
      "|  000087|하이트진로2우B|15710|  0.58|17754467980|2024-03-15|null|null|   null|   null| null|null|    1000.0|      6.37|          4836|        0.43|       1130138|            0.43|15530|15720|15530|   508| 7934080|        null|   KOSPI|  우선주|          null|음식료품|\n",
      "+--------+--------------+-----+------+-----------+----------+----+----+-------+-------+-----+----+----------+----------+--------------+------------+--------------+----------------+-----+-----+-----+------+--------+------------+--------+--------+--------------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "##### isnan() 함수 적용 결과 #####\n",
      "+--------+------+----+------+--------+------+---+---+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "|종목코드|종목명|종가|등락률|시가총액|기준일|eps|per|선행eps|선행per|bps|pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량|거래대금|기업고유번호|시장구분|종목구분|섹터|업종명|\n",
      "+--------+------+----+------+--------+------+---+---+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "+--------+------+----+------+--------+------+---+---+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan\n",
    "\n",
    "#isNull()은 컬럼 조건에 붙어서 filter()메소드와 함께 사용. isnan()은 pyspark.sql.functions의 함수로 사용. \n",
    "print('##### isNull() 적용 결과 #####')\n",
    "# select * from stock_sdf where per is Null\n",
    "stock_sdf.filter(col('per').isNull()).show(3) \n",
    "#stock_sdf.filter('per is Null').show(10)\n",
    "\n",
    "print('##### isnan() 함수 적용 결과 #####')\n",
    "stock_sdf.where(isnan(col('per'))).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "806b3732-7b27-47e9-ac81-ef29486eeb75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  x|   y|\n",
      "+---+----+\n",
      "|1.0|null|\n",
      "|NaN| foo|\n",
      "+---+----+\n",
      "\n",
      "None\n",
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n",
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark DataFrame의 dropna()와 DataFrame.na.drop()은 Null 또는 NaN 모두를 찾아서 삭제해줌. \n",
    "sdf = spark.createDataFrame([(1.0, None), (float('nan'), 'foo')], (\"x\", \"y\"))\n",
    "print(sdf.show())\n",
    "sdf.dropna().show()\n",
    "sdf.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5260fd86-7c2d-4be2-bca3-4e96c270b098",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2671 entries, 0 to 2670\n",
      "Data columns (total 28 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   종목코드      2671 non-null   object \n",
      " 1   종목명       2671 non-null   object \n",
      " 2   종가        2671 non-null   int64  \n",
      " 3   등락률       2671 non-null   float64\n",
      " 4   시가총액      2671 non-null   int64  \n",
      " 5   기준일       2671 non-null   object \n",
      " 6   eps       1600 non-null   float64\n",
      " 7   per       1600 non-null   float64\n",
      " 8   선행eps     511 non-null    float64\n",
      " 9   선행per     511 non-null    float64\n",
      " 10  bps       2381 non-null   float64\n",
      " 11  pbr       2381 non-null   float64\n",
      " 12  주당배당금     2622 non-null   float64\n",
      " 13  배당수익률     2622 non-null   float64\n",
      " 14  외국인보유수량   2671 non-null   int64  \n",
      " 15  외국인지분율    2671 non-null   float64\n",
      " 16  외국인한도수량   2671 non-null   int64  \n",
      " 17  외국인한도소진율  2671 non-null   float64\n",
      " 18  시가        2671 non-null   int64  \n",
      " 19  고가        2671 non-null   int64  \n",
      " 20  저가        2671 non-null   int64  \n",
      " 21  거래량       2671 non-null   int64  \n",
      " 22  거래대금      2671 non-null   int64  \n",
      " 23  기업고유번호    2554 non-null   float64\n",
      " 24  시장구분      2671 non-null   object \n",
      " 25  종목구분      2671 non-null   object \n",
      " 26  섹터        2276 non-null   object \n",
      " 27  업종명       2671 non-null   object \n",
      "dtypes: float64(12), int64(9), object(7)\n",
      "memory usage: 584.4+ KB\n"
     ]
    }
   ],
   "source": [
    "stock_pdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "11159553-89ab-4488-9d09-7e0e454dcb85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Null이 있는 컬럼명과 Null 건수를 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b42918bd-c056-46cc-9e55-370033146069",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+------+--------+------+----+----+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "|종목코드|종목명|종가|등락률|시가총액|기준일| eps| per|선행eps|선행per|bps|pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량|거래대금|기업고유번호|시장구분|종목구분|섹터|업종명|\n",
      "+--------+------+----+------+--------+------+----+----+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "|       0|     0|   0|     0|       0|     0|1071|1071|   2160|   2160|290|290|        49|        49|             0|           0|             0|               0|   0|   0|   0|     0|       0|         117|       0|       0| 395|     0|\n",
      "+--------+------+----+------+--------+------+----+----+-------+-------+---+---+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+--------+------------+--------+--------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, when\n",
    "\n",
    "# select count(case when 종목명 is null then 종목명), count(case when 종가 is null then 종가),,,,, from stock_sdf\n",
    "stock_sdf.select([count(when (col(c).isNull(), c)).alias(c) for c in stock_sdf.columns]).show()\n",
    "\n",
    "\n",
    "# stock_sdf.select([count(when(isnan(c), c)).alias(c) for c in stock_sdf.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f263acc6-ca9c-47bd-b86e-39792d6d4a73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+------+\n",
      "|          종목명|   per|   eps|\n",
      "+----------------+------+------+\n",
      "|        동화약품|  12.7| 736.0|\n",
      "|            경방| 47.85| 177.0|\n",
      "|      삼양홀딩스|  7.77|9173.0|\n",
      "|      하이트진로| 16.24|1250.0|\n",
      "|        유한양행| 58.18|1272.0|\n",
      "|      CJ대한통운| 15.21|8190.0|\n",
      "|하이트진로홀딩스|  6.31|1427.0|\n",
      "|              DL| 16.74|2679.0|\n",
      "|    한국앤컴퍼니|  9.35|1749.0|\n",
      "|      삼천당제약|293.58| 265.0|\n",
      "+----------------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select * from stock_sdf where per is not null\n",
    "stock_sdf.filter(col('per').isNotNull()).select('종목명', 'per', 'eps').show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "11212347-3eb7-447f-ac7b-65b76239699e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  x|   y|\n",
      "+---+----+\n",
      "|1.0|null|\n",
      "|NaN| foo|\n",
      "+---+----+\n",
      "\n",
      "None\n",
      "+----+----+\n",
      "|   x|   y|\n",
      "+----+----+\n",
      "| 1.0|null|\n",
      "|null| foo|\n",
      "+----+----+\n",
      "\n"
     ]
    },
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got NoneType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m sdf\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# fillna(None) 은 오류 발생. \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:4093\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[0;34m(self, value, subset)\u001b[0m\n\u001b[1;32m   4021\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Replace null values, alias for ``na.fill()``.\u001b[39;00m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;124;03m:func:`DataFrame.fillna` and :func:`DataFrameNaFunctions.fill` are aliases of each other.\u001b[39;00m\n\u001b[1;32m   4023\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4090\u001b[0m \u001b[38;5;124;03m+---+------+-------+----+\u001b[39;00m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   4094\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4095\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   4096\u001b[0m     )\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# Note that bool validates isinstance(int), but we don't want to\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;66;03m# convert bools to floats\u001b[39;00m\n\u001b[1;32m   4101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got NoneType."
     ]
    }
   ],
   "source": [
    "# Spark DataFrame의 NaN을 Null로 변환하기. \n",
    "sdf = spark.createDataFrame([(1.0, None), (float('nan'), 'foo')], (\"x\", \"y\"))\n",
    "print(sdf.show())\n",
    "\n",
    "# nan을 null로 변경\n",
    "sdf.replace(float('nan'), None).show()\n",
    "\n",
    "\n",
    "# fillna(None) 은 오류 발생. \n",
    "sdf.fillna(value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "51890150-65a8-4d0d-b1d3-1e1a368666c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 결손(Null) 데이터 처리하기\n",
    "* DataFrame의 fillna() 메소드, 또는 DataFrameNaFunctions 객체인 DataFrame.na의 fill() 메소드를 이용\n",
    "* DataFrame.fillna(value=값, subset=['컬럼1', 컬럼2])로 형태로 사용. value는 결측값에 입력될 값, subset은 대상 컬럼. subset을 지정하지 않으면 전체 컬럼에 적용. \n",
    "* subset을 지정하지 않고 value에 숫자값을 입력하면 숫자형 컬럼만 결손값을 처리함. 비슷하게 value에 문자값을 입력하면 문자형 컬럼만 결손값을 처리함.\n",
    "* value는 반드시 단일 값이 들어가야함. 단일 값을 가지는 DataFrame은 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "77efd4f2-51b1-4f1c-a5b6-09fbc9db7af7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 결측값을 per 변수의 평균값으로 대체\n",
    "stock_pdf['per'] = stock_pdf['per'].fillna(stock_pdf['per'].mean(), inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "475135d1-3453-4d91-a385-ead9ee43ac64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrameNaFunctions"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stock_sdf.na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "600782f7-1672-444f-a107-649fd5c426b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset을 지정하지 않고 숫자형 컬럼에 결측치 처리\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|종목코드|  종목명|종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|  000020|동화약품|9350| -0.85|261159244500|2024-03-15|736.0| 12.7|  999.0|  999.0|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|\n",
      "|  000040|KR모터스| 465|   0.0| 44704386225|2024-03-15|999.0|999.0|  999.0|  999.0|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|\n",
      "|  000050|    경방|8470| -1.63|232207336900|2024-03-15|177.0|47.85|  999.0|  999.0|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|종목코드|  종목명|종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|  000020|동화약품|9350| -0.85|261159244500|2024-03-15|736.0| 12.7|  999.0|  999.0|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|\n",
      "|  000040|KR모터스| 465|   0.0| 44704386225|2024-03-15|999.0|999.0|  999.0|  999.0|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|\n",
      "|  000050|    경방|8470| -1.63|232207336900|2024-03-15|177.0|47.85|  999.0|  999.0|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "subset을 지정하지 않고 문자형 컬럼에 결측치 처리\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|종목코드|  종목명|종가|등락률|    시가총액|    기준일|  eps|  per|선행eps|선행per|    bps| pbr|주당배당금|배당수익률|외국인보유수량|외국인지분율|외국인한도수량|외국인한도소진율|시가|고가|저가|거래량| 거래대금|기업고유번호|시장구분|종목구분|          섹터|  업종명|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "|  000020|동화약품|9350| -0.85|261159244500|2024-03-15|736.0| 12.7|   null|   null|13165.0|0.71|     180.0|      1.93|       1681856|        6.02|      27931470|            6.02|9450|9450|9300| 72206|674278570|      119195|   KOSPI|  보통주|      건강관리|  의약품|\n",
      "|  000040|KR모터스| 465|   0.0| 44704386225|2024-03-15| null| null|   null|   null|  345.0|1.35|       0.0|       0.0|      43963412|       45.73|      96138465|           45.73|   0|   0|   0|     0|        0|      112378|   KOSPI|  보통주|경기관련소비재|운수장비|\n",
      "|  000050|    경방|8470| -1.63|232207336900|2024-03-15|177.0|47.85|   null|   null|30304.0|0.28|     125.0|      1.48|        270629|        0.99|      27415270|            0.99|8610|8690|8270| 11024| 93485040|      101628|   KOSPI|  보통주|경기관련소비재|  유통업|\n",
      "+--------+--------+----+------+------------+----------+-----+-----+-------+-------+-------+----+----------+----------+--------------+------------+--------------+----------------+----+----+----+------+---------+------------+--------+--------+--------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('subset을 지정하지 않고 숫자형 컬럼에 결측치 처리')\n",
    "stock_sdf.fillna(value=999).show(3)\n",
    "stock_sdf.na.fill(value=999).show(3)\n",
    "\n",
    "print('subset을 지정하지 않고 문자형 컬럼에 결측치 처리')\n",
    "stock_sdf.fillna(value='NA').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e942138-62b2-4f71-a8eb-691658ee462b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per 컬럼 결측치 처리\n",
      "+--------------+-----+------+--------------+\n",
      "|        종목명|  per|   eps|          섹터|\n",
      "+--------------+-----+------+--------------+\n",
      "|      동화약품| 12.7| 736.0|      건강관리|\n",
      "|      KR모터스|999.0|  null|경기관련소비재|\n",
      "|          경방|47.85| 177.0|경기관련소비재|\n",
      "|    삼양홀딩스| 7.77|9173.0|          소재|\n",
      "|  삼양홀딩스우|999.0|  null|          null|\n",
      "|    하이트진로|16.24|1250.0|    필수소비재|\n",
      "|하이트진로2우B|999.0|  null|          null|\n",
      "|      유한양행|58.18|1272.0|      건강관리|\n",
      "|    유한양행우|999.0|  null|          null|\n",
      "|    CJ대한통운|15.21|8190.0|        산업재|\n",
      "+--------------+-----+------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "eps 컬럼 결측치 처리\n",
      "+--------------+-----+------+--------------+\n",
      "|        종목명|  per|   eps|          섹터|\n",
      "+--------------+-----+------+--------------+\n",
      "|      동화약품| 12.7| 736.0|      건강관리|\n",
      "|      KR모터스| null| 999.0|경기관련소비재|\n",
      "|          경방|47.85| 177.0|경기관련소비재|\n",
      "|    삼양홀딩스| 7.77|9173.0|          소재|\n",
      "|  삼양홀딩스우| null| 999.0|          null|\n",
      "|    하이트진로|16.24|1250.0|    필수소비재|\n",
      "|하이트진로2우B| null| 999.0|          null|\n",
      "|      유한양행|58.18|1272.0|      건강관리|\n",
      "|    유한양행우| null| 999.0|          null|\n",
      "|    CJ대한통운|15.21|8190.0|        산업재|\n",
      "+--------------+-----+------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('per 컬럼 결측치 처리')\n",
    "stock_sdf.fillna(value=999, subset=['per']).select('종목명', 'per', 'eps', '섹터').show(10) \n",
    "\n",
    "print('eps 컬럼 결측치 처리')\n",
    "# titanic_pdf['Cabin'].fillna('NA', inplace=False)\n",
    "stock_sdf.fillna(value=999, subset=['eps']).select('종목명', 'per', 'eps', '섹터').show(10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1fbc9c98-c928-425d-9ab2-f8ef6f945eb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(per)|\n",
      "+------------------+\n",
      "|51.476893750000045|\n",
      "+------------------+\n",
      "\n",
      "None\n",
      "### avg_per type: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "# select avg(per) from stock_sdf\n",
    "avg_per = stock_sdf.select(F.avg(F.col('per')))\n",
    "print(avg_per.show())\n",
    "print('### avg_per type:', type(avg_per))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6acd7bad-1f56-4882-b00b-17477d921381",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 아래는 오류를 발생시킴. value 인자로 단일 값이 입력되어야 함. DataFrame은 입력 될 수 없음. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstock_sdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavg_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:4093\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[0;34m(self, value, subset)\u001b[0m\n\u001b[1;32m   4021\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Replace null values, alias for ``na.fill()``.\u001b[39;00m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;124;03m:func:`DataFrame.fillna` and :func:`DataFrameNaFunctions.fill` are aliases of each other.\u001b[39;00m\n\u001b[1;32m   4023\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4090\u001b[0m \u001b[38;5;124;03m+---+------+-------+----+\u001b[39;00m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   4094\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4095\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   4096\u001b[0m     )\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# Note that bool validates isinstance(int), but we don't want to\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;66;03m# convert bools to floats\u001b[39;00m\n\u001b[1;32m   4101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got DataFrame."
     ]
    }
   ],
   "source": [
    "# 아래는 오류를 발생시킴. value 인자로 단일 값이 입력되어야 함. DataFrame은 입력 될 수 없음. \n",
    "stock_sdf.fillna(value=avg_per, subset=['per'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e492cba7-aa11-47ca-bfcb-2242eb16b35d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(avg(per)=51.476893750000045) <class 'pyspark.sql.types.Row'>\n",
      "\n",
      "51.476893750000045 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# first()는 head()와 동일하게 동작. 하지만 first(N)은 존재하지 않으며 first()는 맨 처음 Row만 가져옴. \n",
    "avg_per_row = avg_per.first()\n",
    "print(avg_per_row, type(avg_per_row))\n",
    "print()\n",
    "\n",
    "# 아래는 DataFrame의 단일 Row에서 맨 첫번째 개별 value를 가져옴. \n",
    "avg_per_value = avg_per.first()[0]\n",
    "print(avg_per_value, type(avg_per_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "66abfd11-f44c-4091-80ee-aff0df40ff06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+--------------+\n",
      "|        종목명|               per|          섹터|\n",
      "+--------------+------------------+--------------+\n",
      "|      동화약품|              12.7|      건강관리|\n",
      "|      KR모터스|51.476893750000045|경기관련소비재|\n",
      "|          경방|             47.85|경기관련소비재|\n",
      "|    삼양홀딩스|              7.77|          소재|\n",
      "|  삼양홀딩스우|51.476893750000045|          null|\n",
      "|    하이트진로|             16.24|    필수소비재|\n",
      "|하이트진로2우B|51.476893750000045|          null|\n",
      "|      유한양행|             58.18|      건강관리|\n",
      "|    유한양행우|51.476893750000045|          null|\n",
      "|    CJ대한통운|             15.21|        산업재|\n",
      "+--------------+------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_sdf.fillna(value=avg_per_value, subset=['per']).select('종목명', 'per', '섹터').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "48c1787e-109b-4b3d-8f07-ba64e0759aae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 사용자 정의 함수(User Defined Function)을 DataFrame 가공 시 적용하는 법과 when 사용법\n",
    "* UDF를 Spark DataFrame에 적용하려면 먼저 일반 함수를 만든 후에 이를 spark의 udf() 함수를 이용하여 DataFrame에서 사용할 수 있도록 변환해야 함. \n",
    "* pyspark.sql.functions의 when()은 SQL의 Case When Then... Else 구문과 동일하게 동작."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cd704905-6c9b-400d-b291-d30c9430f364",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "avg_age = titanic_sdf.select(F.avg(F.col('Age')))\n",
    "avg_age_row = avg_age.head()\n",
    "avg_age_value = avg_age.head()[0]\n",
    "\n",
    "# Spark DataFrame의 fillna()에 인자로 Dict를 입력하여 여러개의 컬럼들에 대해서 결측치 값을 입력할 수 있게 만들어줌. \n",
    "titanic_sdf_filled = titanic_sdf.fillna({'Age': avg_age_value, \n",
    "                                         'Cabin': 'C000',\n",
    "                                         'Embarked': 'S'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "465d2150-3a1f-46f2-9003-2914403640cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
       "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25| C000|       S|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925| C000|       S|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1| C123|       S|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05| C000|       S|\n",
       "|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583| C000|       Q|\n",
       "|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
       "|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075| C000|       S|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333| C000|       S|\n",
       "|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708| C000|       C|\n",
       "|         11|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
       "|         12|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|          113783|  26.55| C103|       S|\n",
       "|         13|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|       A/5. 2151|   8.05| C000|       S|\n",
       "|         14|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5|          347082| 31.275| C000|       S|\n",
       "|         15|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0|          350406| 7.8542| C000|       S|\n",
       "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|          248706|   16.0| C000|       S|\n",
       "|         17|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1|          382652| 29.125| C000|       Q|\n",
       "|         18|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|          244373|   13.0| C000|       S|\n",
       "|         19|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|          345763|   18.0| C000|       S|\n",
       "|         20|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|            2649|  7.225| C000|       C|\n",
       "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25| C000|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925| C000|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05| C000|       S|\n|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583| C000|       Q|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|  E46|       S|\n|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075| C000|       S|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333| C000|       S|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708| C000|       C|\n|         11|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n|         12|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|          113783|  26.55| C103|       S|\n|         13|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|       A/5. 2151|   8.05| C000|       S|\n|         14|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5|          347082| 31.275| C000|       S|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0|          350406| 7.8542| C000|       S|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|          248706|   16.0| C000|       S|\n|         17|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1|          382652| 29.125| C000|       Q|\n|         18|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|          244373|   13.0| C000|       S|\n|         19|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|          345763|   18.0| C000|       S|\n|         20|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|            2649|  7.225| C000|       C|\n+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data",
     "transient": null
    }
   ],
   "source": [
    "titanic_sdf_filled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "14f8ea42-19d5-4108-b54c-ed1d6bbc3dbc",
     "showTitle": false,
     "title": "python용 UDF를 작성"
    }
   },
   "outputs": [],
   "source": [
    "# 일반 python용 UDF를 작성. 반드시 입력 값과 반환 값을 설정\n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    \n",
    "    # age 값이 None일 경우는 NA를 Return\n",
    "    #if age == None:\n",
    "        #return 'NA'\n",
    "    \n",
    "    if age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54a04405-c7ee-40fc-ab23-0f027842da27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Elderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Age_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>None</td>\n      <td>S</td>\n      <td>Student</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Adult</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>None</td>\n      <td>S</td>\n      <td>Young Adult</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Young Adult</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>None</td>\n      <td>S</td>\n      <td>Young Adult</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>None</td>\n      <td>Q</td>\n      <td>Elderly</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n      <td>Adult</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>None</td>\n      <td>S</td>\n      <td>Baby</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>None</td>\n      <td>S</td>\n      <td>Young Adult</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>None</td>\n      <td>C</td>\n      <td>Teenager</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data",
     "transient": null
    }
   ],
   "source": [
    "# pandas DataFrame에서 apply lambda 식으로 데이터 가공하기. age 값이 None/NaN 일 경우에도 else 조건에 의해 Elderly로 변환. \n",
    "titanic_pdf['Age_category'] = titanic_pdf['Age'].apply(lambda x: get_category(x))\n",
    "titanic_pdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ebdd20c0-585e-49b1-b722-65572280473f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# 일반 python용 UDF를 pyspark용 UDF로 변환. udf(lambda 입력변수: 일반 UDF, 해당 일반 UDF의 반환형)\n",
    "udf_get_category = udf(lambda x:get_category(x), StringType() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ac434c8-b553-474c-9b1b-5d0df508d329",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Age_Category|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Student|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       Adult|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Young Adult|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| Young Adult|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| Young Adult|\n",
       "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|          NA|\n",
       "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|       Adult|\n",
       "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|        Baby|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S| Young Adult|\n",
       "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Teenager|\n",
       "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|        Baby|\n",
       "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|       Adult|\n",
       "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Student|\n",
       "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|       Adult|\n",
       "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|    Teenager|\n",
       "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|       Adult|\n",
       "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|        Baby|\n",
       "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|          NA|\n",
       "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S| Young Adult|\n",
       "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|          NA|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Age_Category|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Student|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       Adult|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Young Adult|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| Young Adult|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| Young Adult|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|          NA|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|       Adult|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|        Baby|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S| Young Adult|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|    Teenager|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|        Baby|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|       Adult|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Student|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|       Adult|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|    Teenager|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|       Adult|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|        Baby|\n|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|          NA|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S| Young Adult|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|          NA|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data",
     "transient": null
    }
   ],
   "source": [
    "# udf_get_category()에 Age 컬럼값을 입력하여 반환되는 값으로 새로운 컬럼 Age_Category를 생성\n",
    "titanic_sdf_filled_01 = titanic_sdf_filled.withColumn(\"Age_Category\",udf_get_category(col(\"Age\")))\n",
    "titanic_sdf_filled_01.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "368c7597-3bcb-4b3b-8a7b-eae66a345fe1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Age_category|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Student|\n",
       "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       Adult|\n",
       "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Young Adult|\n",
       "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| Young Adult|\n",
       "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| Young Adult|\n",
       "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|          NA|\n",
       "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|       Adult|\n",
       "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|        Baby|\n",
       "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S| Young Adult|\n",
       "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|     Teenage|\n",
       "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Age_category|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Student|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       Adult|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Young Adult|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| Young Adult|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| Young Adult|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|          NA|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|       Adult|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|        Baby|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S| Young Adult|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|     Teenage|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data",
     "transient": null
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "                   \n",
    "titanic_sdf_filled_02 = titanic_sdf_filled.withColumn('Age_category', when(F.col('Age') <= 5, 'Baby')\n",
    "                                                                      .when(F.col('Age') <= 12, 'Child')\n",
    "                                                                      .when(F.col('Age') <= 18, 'Teenage')\n",
    "                                                                      .when(F.col('Age') <= 25, 'Student')\n",
    "                                                                      .when(F.col('Age') <= 35, 'Young Adult')\n",
    "                                                                      .when(F.col('Age') <= 60, 'Adult')\n",
    "                                                                      .when(F.col('Age').isNull(), 'NA')\n",
    "                                                                      .otherwise('Elderly'))\n",
    "\n",
    "titanic_sdf_filled_02.limit(10).show()\n",
    "\n",
    "''' Select a.*, CASE WHEN age <=6 THEN 'Baby'\n",
    "                 WHEN age <=12 Then 'Child'\n",
    "                 WHEN age <= 18 THEN 'Teenage'\n",
    "                 WHEN age <= 25 THEN 'Student'\n",
    "                 WHEN age <=35 THEN 'Young Adult'\n",
    "                 WHEN age <=60 THEN 'Adult'\n",
    "                 WHEN age is Null THEN 'NA'\n",
    "                 ELSE 'Elderly' END from titanic_sdf a;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "618f1d23-8558-4274-b511-ca5bf6bca4f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "440f9f67-f451-45a1-9dfc-a803e25344ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)\n",
       "\u001b[0;32m<command-2719872723043665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;32m----> 3\u001b[0;31m titanic_sdf_filled_03 = titanic_sdf.withColumn('Age_category', expr(\"CASE WHEN age = 12 THEN 'Child' \" + \\\n",
       "\u001b[0m\u001b[1;32m      4\u001b[0m                                                \u001b[0;34m\" WHEN Age <= 18 THEN 'Teenage' \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m      5\u001b[0m                                                \u001b[0;34m\" WHEN Age <= 25 THEN 'Student' \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\n",
       "\u001b[0;32m/databricks/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mexpr\u001b[0;34m(str)\u001b[0m\n",
       "\u001b[1;32m   1457\u001b[0m     \"\"\"\n",
       "\u001b[1;32m   1458\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
       "\n",
       "\u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n",
       "\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n",
       "\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
       "\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
       "\n",
       "\u001b[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n",
       "\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[1;32m    125\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\n",
       "\u001b[0;31mParseException\u001b[0m: \n",
       "mismatched input 'age' expecting {<EOF>, '-'}(line 1, pos 10)\n",
       "\n",
       "== SQL ==\n",
       "CASE WHEN age = 12 THEN 'Child'  WHEN Age <= 18 THEN 'Teenage'  WHEN Age <= 25 THEN 'Student'  WHEN Age <= 35 THEN 'Young Adult'  WHEN Age <= 60 THEN 'Adult'  WHEN Age IS NULL THEN 'NA'  ELSE 'Elderly' \n",
       "----------^^^\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)\n\u001b[0;32m<command-2719872723043665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m titanic_sdf_filled_03 = titanic_sdf.withColumn('Age_category', expr(\"CASE WHEN age = 12 THEN 'Child' \" + \\\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                \u001b[0;34m\" WHEN Age <= 18 THEN 'Teenage' \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                \u001b[0;34m\" WHEN Age <= 25 THEN 'Student' \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/databricks/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mexpr\u001b[0;34m(str)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \"\"\"\n\u001b[1;32m   1458\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mParseException\u001b[0m: \nmismatched input 'age' expecting {<EOF>, '-'}(line 1, pos 10)\n\n== SQL ==\nCASE WHEN age = 12 THEN 'Child'  WHEN Age <= 18 THEN 'Teenage'  WHEN Age <= 25 THEN 'Student'  WHEN Age <= 35 THEN 'Young Adult'  WHEN Age <= 60 THEN 'Adult'  WHEN Age IS NULL THEN 'NA'  ELSE 'Elderly' \n----------^^^\n",
       "errorSummary": "<span class='ansi-red-fg'>ParseException</span>: \nmismatched input 'age' expecting {<EOF>, '-'}(line 1, pos 10)\n\n== SQL ==\nCASE WHEN age = 12 THEN 'Child'  WHEN Age <= 18 THEN 'Teenage'  WHEN Age <= 25 THEN 'Student'  WHEN Age <= 35 THEN 'Young Adult'  WHEN Age <= 60 THEN 'Adult'  WHEN Age IS NULL THEN 'NA'  ELSE 'Elderly' \n----------^^^\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data",
     "transient": null
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "titanic_sdf_filled_03 = titanic_sdf.withColumn('Age_category', expr(\"CASE WHEN age = 12 THEN 'Child' \" + \n",
    "                                               \" WHEN Age <= 18 THEN 'Teenage' \" +\n",
    "                                               \" WHEN Age <= 25 THEN 'Student' \" +\n",
    "                                               \" WHEN Age <= 35 THEN 'Young Adult' \" + \n",
    "                                               \" WHEN Age <= 60 THEN 'Adult' \" + \n",
    "                                               \" WHEN Age IS NULL THEN 'NA' \" +\n",
    "                                               \" ELSE 'Elderly' \"))\n",
    "titanic_sdf_filled_03.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e7256c2-8ca1-4ba5-bc58-786edeb4bcab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f3 = df.withColumn(\"new_gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" + \n",
    "               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n",
    "               \"ELSE gender END\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark_dataframe_exercise_03 (1)",
   "notebookOrigID": 1656680289675112,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
